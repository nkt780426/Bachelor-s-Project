{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 14:21:08.415261: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-19 14:21:09.703979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from going_modular.model.TripletFaceRecognition import EmbeddingNet, TripletNet\n",
    "from going_modular.dataloader.triplet import TripletDataset, GaussianNoise, RandomResizedCropRect\n",
    "from going_modular.loss.TripletLoss import TripletLoss\n",
    "from going_modular.train_eval.triplet.train import fit\n",
    "from going_modular.dataloader.triplet import CustomExrDataset\n",
    "from going_modular.utils.MultiMetricEarlyStopping import MultiMetricEarlyStopping\n",
    "from going_modular.utils.ModelCheckPoint import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Đặt seed toàn cục\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "CONFIGURATION = {\n",
    "    # Thư mục\n",
    "    'type': 'albedo',\n",
    "    'train_dir': './Dataset/Albedo/train',\n",
    "    'test_dir': './Dataset/Albedo/test',\n",
    "    \n",
    "    # Cấu hình train\n",
    "    'epochs': 400,\n",
    "    'num_workers': 4,\n",
    "    'batch_size': 16,\n",
    "    'image_size': 256,\n",
    "    'embedding_size': 512,\n",
    "    \n",
    "    'start_lr': 1e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'alpha': 0.9,\n",
    "    \n",
    "    # triplet\n",
    "    'margin': 1.,\n",
    "}\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    RandomResizedCropRect(size=CONFIGURATION['image_size']),\n",
    "    GaussianNoise(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIGURATION['image_size'], CONFIGURATION['image_size']), interpolation=InterpolationMode.BILINEAR),\n",
    "])\n",
    "\n",
    "triplet_train_dataset = TripletDataset(data_dir=CONFIGURATION['train_dir'], transform=train_transform, train=True)\n",
    "triplet_test_dataset = TripletDataset(data_dir=CONFIGURATION['train_dir'], transform=test_transform, train=False)\n",
    "\n",
    "triplet_train_loader = DataLoader(\n",
    "    triplet_train_dataset, \n",
    "    batch_size=CONFIGURATION['batch_size'], \n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "triplet_test_loader = DataLoader(\n",
    "    triplet_test_dataset, \n",
    "    batch_size=CONFIGURATION['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "roc_train_dataset = CustomExrDataset(CONFIGURATION['train_dir'], transform=train_transform, type=CONFIGURATION['type'])\n",
    "roc_train_loader = DataLoader(\n",
    "    roc_train_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    ")\n",
    "\n",
    "roc_test_dataset = CustomExrDataset(CONFIGURATION['test_dir'], transform=test_transform, type=CONFIGURATION['type'])\n",
    "roc_test_loader = DataLoader(\n",
    "    roc_test_dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=CONFIGURATION['batch_size'],\n",
    ")\n",
    "\n",
    "embedding_net = EmbeddingNet(len_embedding=CONFIGURATION['embedding_size']).to(device)\n",
    "model = TripletNet(embedding_net).to(device)\n",
    "criterion = TripletLoss(CONFIGURATION['margin'])\n",
    "optimizer = Adam(model.parameters(), lr=CONFIGURATION['start_lr'])\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "earlystop_dir = os.path.abspath('checkpoint/triplet/' + CONFIGURATION['type'] + '/models')\n",
    "early_min_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['test_loss'],\n",
    "    patience=50,\n",
    "    mode='min',\n",
    "    verbose=0,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=10\n",
    ")      \n",
    "\n",
    "early_max_stopping = MultiMetricEarlyStopping(\n",
    "    monitor_keys=['cosine_auc', 'cosine_acc', 'euclidean_auc', 'euclidean_acc'],\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_dir=earlystop_dir,\n",
    "    start_from_epoch=20\n",
    ")      \n",
    "\n",
    "checkpoint_path = os.path.abspath('checkpoint/triplet/' + CONFIGURATION['type'] + '/models/checkpoint.pth')\n",
    "modle_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/52\n",
      "Batch 1: Anchors shape torch.Size([16, 512])\n",
      "Batch 1: Loss computed\n",
      "Batch 1: Loss value 157.66543579101562\n",
      "Batch 1: Backward pass done\n",
      "Batch 1: Optimizer step done\n",
      "Processing batch 2/52\n",
      "Batch 2: Anchors shape torch.Size([16, 512])\n",
      "Batch 2: Loss computed\n",
      "Batch 2: Loss value 106.80268859863281\n",
      "Batch 2: Backward pass done\n",
      "Batch 2: Optimizer step done\n",
      "Processing batch 3/52\n",
      "Batch 3: Anchors shape torch.Size([16, 512])\n",
      "Batch 3: Loss computed\n",
      "Batch 3: Loss value 81.90013122558594\n",
      "Batch 3: Backward pass done\n",
      "Batch 3: Optimizer step done\n",
      "Processing batch 4/52\n",
      "Batch 4: Anchors shape torch.Size([16, 512])\n",
      "Batch 4: Loss computed\n",
      "Batch 4: Loss value 51.162384033203125\n",
      "Batch 4: Backward pass done\n",
      "Batch 4: Optimizer step done\n",
      "Processing batch 5/52\n",
      "Batch 5: Anchors shape torch.Size([16, 512])\n",
      "Batch 5: Loss computed\n",
      "Batch 5: Loss value 42.900482177734375\n",
      "Batch 5: Backward pass done\n",
      "Batch 5: Optimizer step done\n",
      "Processing batch 6/52\n",
      "Batch 6: Anchors shape torch.Size([16, 512])\n",
      "Batch 6: Loss computed\n",
      "Batch 6: Loss value 52.850975036621094\n",
      "Batch 6: Backward pass done\n",
      "Batch 6: Optimizer step done\n",
      "Processing batch 7/52\n",
      "Batch 7: Anchors shape torch.Size([16, 512])\n",
      "Batch 7: Loss computed\n",
      "Batch 7: Loss value 40.59270477294922\n",
      "Batch 7: Backward pass done\n",
      "Batch 7: Optimizer step done\n",
      "Processing batch 8/52\n",
      "Batch 8: Anchors shape torch.Size([16, 512])\n",
      "Batch 8: Loss computed\n",
      "Batch 8: Loss value 51.325645446777344\n",
      "Batch 8: Backward pass done\n",
      "Batch 8: Optimizer step done\n",
      "Processing batch 9/52\n",
      "Batch 9: Anchors shape torch.Size([16, 512])\n",
      "Batch 9: Loss computed\n",
      "Batch 9: Loss value 15.37729263305664\n",
      "Batch 9: Backward pass done\n",
      "Batch 9: Optimizer step done\n",
      "Processing batch 10/52\n",
      "Batch 10: Anchors shape torch.Size([16, 512])\n",
      "Batch 10: Loss computed\n",
      "Batch 10: Loss value 24.378503799438477\n",
      "Batch 10: Backward pass done\n",
      "Batch 10: Optimizer step done\n",
      "Processing batch 11/52\n",
      "Batch 11: Anchors shape torch.Size([16, 512])\n",
      "Batch 11: Loss computed\n",
      "Batch 11: Loss value 39.327850341796875\n",
      "Batch 11: Backward pass done\n",
      "Batch 11: Optimizer step done\n",
      "Processing batch 12/52\n",
      "Batch 12: Anchors shape torch.Size([16, 512])\n",
      "Batch 12: Loss computed\n",
      "Batch 12: Loss value 24.37474250793457\n",
      "Batch 12: Backward pass done\n",
      "Batch 12: Optimizer step done\n",
      "Processing batch 13/52\n",
      "Batch 13: Anchors shape torch.Size([16, 512])\n",
      "Batch 13: Loss computed\n",
      "Batch 13: Loss value 36.81629943847656\n",
      "Batch 13: Backward pass done\n",
      "Batch 13: Optimizer step done\n",
      "Processing batch 14/52\n",
      "Batch 14: Anchors shape torch.Size([16, 512])\n",
      "Batch 14: Loss computed\n",
      "Batch 14: Loss value 39.573394775390625\n",
      "Batch 14: Backward pass done\n",
      "Batch 14: Optimizer step done\n",
      "Processing batch 15/52\n",
      "Batch 15: Anchors shape torch.Size([16, 512])\n",
      "Batch 15: Loss computed\n",
      "Batch 15: Loss value 11.832462310791016\n",
      "Batch 15: Backward pass done\n",
      "Batch 15: Optimizer step done\n",
      "Processing batch 16/52\n",
      "Batch 16: Anchors shape torch.Size([16, 512])\n",
      "Batch 16: Loss computed\n",
      "Batch 16: Loss value 16.40912628173828\n",
      "Batch 16: Backward pass done\n",
      "Batch 16: Optimizer step done\n",
      "Processing batch 17/52\n",
      "Batch 17: Anchors shape torch.Size([16, 512])\n",
      "Batch 17: Loss computed\n",
      "Batch 17: Loss value 17.83187484741211\n",
      "Batch 17: Backward pass done\n",
      "Batch 17: Optimizer step done\n",
      "Processing batch 18/52\n",
      "Batch 18: Anchors shape torch.Size([16, 512])\n",
      "Batch 18: Loss computed\n",
      "Batch 18: Loss value 18.544504165649414\n",
      "Batch 18: Backward pass done\n",
      "Batch 18: Optimizer step done\n",
      "Processing batch 19/52\n",
      "Batch 19: Anchors shape torch.Size([16, 512])\n",
      "Batch 19: Loss computed\n",
      "Batch 19: Loss value 18.755386352539062\n",
      "Batch 19: Backward pass done\n",
      "Batch 19: Optimizer step done\n",
      "Processing batch 20/52\n",
      "Batch 20: Anchors shape torch.Size([16, 512])\n",
      "Batch 20: Loss computed\n",
      "Batch 20: Loss value 32.76392364501953\n",
      "Batch 20: Backward pass done\n",
      "Batch 20: Optimizer step done\n",
      "Processing batch 21/52\n",
      "Batch 21: Anchors shape torch.Size([16, 512])\n",
      "Batch 21: Loss computed\n",
      "Batch 21: Loss value 27.10201072692871\n",
      "Batch 21: Backward pass done\n",
      "Batch 21: Optimizer step done\n",
      "Processing batch 22/52\n",
      "Batch 22: Anchors shape torch.Size([16, 512])\n",
      "Batch 22: Loss computed\n",
      "Batch 22: Loss value 20.0369930267334\n",
      "Batch 22: Backward pass done\n",
      "Batch 22: Optimizer step done\n",
      "Processing batch 23/52\n",
      "Batch 23: Anchors shape torch.Size([16, 512])\n",
      "Batch 23: Loss computed\n",
      "Batch 23: Loss value 20.99163246154785\n",
      "Batch 23: Backward pass done\n",
      "Batch 23: Optimizer step done\n",
      "Processing batch 24/52\n",
      "Batch 24: Anchors shape torch.Size([16, 512])\n",
      "Batch 24: Loss computed\n",
      "Batch 24: Loss value 16.490976333618164\n",
      "Batch 24: Backward pass done\n",
      "Batch 24: Optimizer step done\n",
      "Processing batch 25/52\n",
      "Batch 25: Anchors shape torch.Size([16, 512])\n",
      "Batch 25: Loss computed\n",
      "Batch 25: Loss value 20.021465301513672\n",
      "Batch 25: Backward pass done\n",
      "Batch 25: Optimizer step done\n",
      "Processing batch 26/52\n",
      "Batch 26: Anchors shape torch.Size([16, 512])\n",
      "Batch 26: Loss computed\n",
      "Batch 26: Loss value 26.67804527282715\n",
      "Batch 26: Backward pass done\n",
      "Batch 26: Optimizer step done\n",
      "Processing batch 27/52\n",
      "Batch 27: Anchors shape torch.Size([16, 512])\n",
      "Batch 27: Loss computed\n",
      "Batch 27: Loss value 35.03324890136719\n",
      "Batch 27: Backward pass done\n",
      "Batch 27: Optimizer step done\n",
      "Processing batch 28/52\n",
      "Batch 28: Anchors shape torch.Size([16, 512])\n",
      "Batch 28: Loss computed\n",
      "Batch 28: Loss value 19.070724487304688\n",
      "Batch 28: Backward pass done\n",
      "Batch 28: Optimizer step done\n",
      "Processing batch 29/52\n",
      "Batch 29: Anchors shape torch.Size([16, 512])\n",
      "Batch 29: Loss computed\n",
      "Batch 29: Loss value 22.01970100402832\n",
      "Batch 29: Backward pass done\n",
      "Batch 29: Optimizer step done\n",
      "Processing batch 30/52\n",
      "Batch 30: Anchors shape torch.Size([16, 512])\n",
      "Batch 30: Loss computed\n",
      "Batch 30: Loss value 30.89849281311035\n",
      "Batch 30: Backward pass done\n",
      "Batch 30: Optimizer step done\n",
      "Processing batch 31/52\n",
      "Batch 31: Anchors shape torch.Size([16, 512])\n",
      "Batch 31: Loss computed\n",
      "Batch 31: Loss value 7.7253265380859375\n",
      "Batch 31: Backward pass done\n",
      "Batch 31: Optimizer step done\n",
      "Processing batch 32/52\n",
      "Batch 32: Anchors shape torch.Size([16, 512])\n",
      "Batch 32: Loss computed\n",
      "Batch 32: Loss value 7.088008880615234\n",
      "Batch 32: Backward pass done\n",
      "Batch 32: Optimizer step done\n",
      "Processing batch 33/52\n",
      "Batch 33: Anchors shape torch.Size([16, 512])\n",
      "Batch 33: Loss computed\n",
      "Batch 33: Loss value 14.59075927734375\n",
      "Batch 33: Backward pass done\n",
      "Batch 33: Optimizer step done\n",
      "Processing batch 34/52\n",
      "Batch 34: Anchors shape torch.Size([16, 512])\n",
      "Batch 34: Loss computed\n",
      "Batch 34: Loss value 15.910102844238281\n",
      "Batch 34: Backward pass done\n",
      "Batch 34: Optimizer step done\n",
      "Processing batch 35/52\n",
      "Batch 35: Anchors shape torch.Size([16, 512])\n",
      "Batch 35: Loss computed\n",
      "Batch 35: Loss value 9.371662139892578\n",
      "Batch 35: Backward pass done\n",
      "Batch 35: Optimizer step done\n",
      "Processing batch 36/52\n",
      "Batch 36: Anchors shape torch.Size([16, 512])\n",
      "Batch 36: Loss computed\n",
      "Batch 36: Loss value 13.02076530456543\n",
      "Batch 36: Backward pass done\n",
      "Batch 36: Optimizer step done\n"
     ]
    }
   ],
   "source": [
    "fit(\n",
    "    conf=CONFIGURATION,\n",
    "    start_epoch=0,\n",
    "    model=model,\n",
    "    triplet_train_loader=triplet_train_loader, \n",
    "    triplet_test_loader=triplet_test_loader, \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler, \n",
    "    epochs=CONFIGURATION['epochs'], \n",
    "    device=device, \n",
    "    roc_train_loader=roc_train_loader, \n",
    "    roc_test_loader=roc_test_loader,\n",
    "    early_max_stopping=early_max_stopping,\n",
    "    early_min_stopping=early_min_stopping,\n",
    "    model_checkpoint=modle_checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
